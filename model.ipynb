{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPU not found. Running on CPU/GPU.\n",
      "Class Weights: {0: 0.5535342538064367, 1: 4.121625273294519, 2: 1.0517411064096536}\n",
      "\n",
      "Comparing feature sets...\n",
      "\n",
      "Training with feature set: Base Features\n",
      "Use /var/folders/4t/vgrmglh57ds018mbdc9875y80000gn/T/tmp51dmbhsx as temporary training directory\n",
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.568218. Found 429513 examples.\n",
      "Reading validation dataset...\n",
      "Num validation examples: tf.Tensor(107379, shape=(), dtype=int32)\n",
      "Validation dataset read in 0:00:00.185946. Found 107379 examples.\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1738059516.455788 1330287 kernel.cc:782] Start Yggdrasil model training\n",
      "I0000 00:00:1738059516.456842 1330287 kernel.cc:783] Collect training examples\n",
      "I0000 00:00:1738059516.456849 1330287 kernel.cc:795] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1738059516.458950 1330287 kernel.cc:401] Number of batches: 420\n",
      "I0000 00:00:1738059516.458956 1330287 kernel.cc:402] Number of examples: 429513\n",
      "I0000 00:00:1738059516.477332 1330287 kernel.cc:802] Training dataset:\n",
      "Number of records: 429513\n",
      "Number of columns: 6\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 5 (83.3333%)\n",
      "\tCATEGORICAL: 1 (16.6667%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 5 (83.3333%)\n",
      "\t1: \"__WEIGHTS\" NUMERICAL mean:0.999494 min:0.553534 max:4.12163 sd:0.952719\n",
      "\t2: \"data:0.0\" NUMERICAL mean:14.9895 min:0 max:30 sd:8.6562\n",
      "\t3: \"data:0.1\" NUMERICAL mean:49.6553 min:-51.31 max:100 sd:19.5554\n",
      "\t4: \"data:0.2\" NUMERICAL mean:449.72 min:100 max:800 sd:201.913\n",
      "\t5: \"data:0.3\" NUMERICAL mean:50.0138 min:-17.72 max:122.11 sd:15.0098\n",
      "\n",
      "CATEGORICAL: 1 (16.6667%)\n",
      "\t0: \"__LABEL\" CATEGORICAL integerized vocab-size:4 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1738059516.477426 1330287 kernel.cc:807] Collect validation dataset\n",
      "I0000 00:00:1738059516.477453 1330287 kernel.cc:401] Number of batches: 105\n",
      "I0000 00:00:1738059516.477456 1330287 kernel.cc:402] Number of examples: 107379\n",
      "I0000 00:00:1738059516.482324 1330287 kernel.cc:813] Validation dataset:\n",
      "Number of records: 107379\n",
      "Number of columns: 6\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 5 (83.3333%)\n",
      "\tCATEGORICAL: 1 (16.6667%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 5 (83.3333%)\n",
      "\t1: \"__WEIGHTS\" NUMERICAL mean:1.00169 min:0.553534 max:4.12163 sd:0.955654\n",
      "\t2: \"data:0.0\" NUMERICAL mean:14.9985 min:0 max:30 sd:8.67014\n",
      "\t3: \"data:0.1\" NUMERICAL mean:49.6671 min:-37.57 max:100 sd:19.5567\n",
      "\t4: \"data:0.2\" NUMERICAL mean:449.234 min:100.01 max:800 sd:202.216\n",
      "\t5: \"data:0.3\" NUMERICAL mean:49.9831 min:-13.24 max:113.16 sd:15.0208\n",
      "\n",
      "CATEGORICAL: 1 (16.6667%)\n",
      "\t0: \"__LABEL\" CATEGORICAL integerized vocab-size:4 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1738059516.482355 1330287 kernel.cc:818] Configure learner\n",
      "I0000 00:00:1738059516.482706 1330287 kernel.cc:831] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^data:0\\\\.0$\"\n",
      "features: \"^data:0\\\\.1$\"\n",
      "features: \"^data:0\\\\.2$\"\n",
      "features: \"^data:0\\\\.3$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "weight_definition {\n",
      "  attribute: \"__WEIGHTS\"\n",
      "  numerical {\n",
      "  }\n",
      "}\n",
      "random_seed: 42\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 50\n",
      "  decision_tree {\n",
      "    max_depth: 7\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1738059516.483101 1330287 kernel.cc:834] Deployment config:\n",
      "cache_path: \"/var/folders/4t/vgrmglh57ds018mbdc9875y80000gn/T/tmp51dmbhsx/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1738059516.483294 1333475 kernel.cc:895] Train model\n",
      "I0000 00:00:1738059516.483955 1333475 random_forest.cc:427] Training random forest on 429513 example(s) and 4 feature(s).\n",
      "I0000 00:00:1738059516.836933 1333487 random_forest.cc:811] Training of tree  1/50 (tree index:3) done accuracy:0.982973 logloss:0.613699\n",
      "I0000 00:00:1738059517.173983 1333481 random_forest.cc:811] Training of tree  11/50 (tree index:10) done accuracy:0.982488 logloss:0.630418\n",
      "I0000 00:00:1738059517.477180 1333483 random_forest.cc:811] Training of tree  21/50 (tree index:21) done accuracy:0.982661 logloss:0.627591\n",
      "I0000 00:00:1738059517.756331 1333484 random_forest.cc:811] Training of tree  31/50 (tree index:31) done accuracy:0.982673 logloss:0.628309\n",
      "I0000 00:00:1738059518.022654 1333486 random_forest.cc:811] Training of tree  41/50 (tree index:40) done accuracy:0.982675 logloss:0.628445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained in 0:00:01.824971\n",
      "Compiling model...\n",
      "Model compiled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1738059518.256316 1333487 random_forest.cc:811] Training of tree  50/50 (tree index:49) done accuracy:0.982675 logloss:0.628853\n",
      "I0000 00:00:1738059518.256371 1333475 random_forest.cc:891] Final OOB metrics: accuracy:0.982675 logloss:0.628853\n",
      "I0000 00:00:1738059518.258873 1333475 kernel.cc:926] Export model in log directory: /var/folders/4t/vgrmglh57ds018mbdc9875y80000gn/T/tmp51dmbhsx with prefix c9a437b61349469b\n",
      "I0000 00:00:1738059518.260942 1333475 kernel.cc:944] Save model in resources\n",
      "I0000 00:00:1738059518.264140 1330287 abstract_model.cc:914] Model self evaluation:\n",
      "Number of predictions (without weights): 429513\n",
      "Number of predictions (with weights): 429296\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.982675  CI95[W][0.982344 0.983001]\n",
      "LogLoss: : 0.628853\n",
      "ErrorRate: : 0.0173253\n",
      "\n",
      "Default Accuracy: : 0.333599\n",
      "Default LogLoss: : 1.09861\n",
      "Default ErrorRate: : 0.666401\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "                   1                  2                  3\n",
      "1  141648.8659880161  372.5285632610321   1191.20574760437\n",
      "2                  0   142929.726433754                  0\n",
      "3                  0     5873.974173069  137279.5618467331\n",
      "Total: 429295.8627524376\n",
      "\n",
      "\n",
      "2025-01-28 11:18:38.270936: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1206] Loading model from path /var/folders/4t/vgrmglh57ds018mbdc9875y80000gn/T/tmp51dmbhsx/model/ with prefix c9a437b61349469b\n",
      "I0000 00:00:1738059518.277208 1330287 decision_forest.cc:761] Model loaded with 50 root(s), 1756 node(s), and 4 input feature(s).\n",
      "I0000 00:00:1738059518.277456 1330287 abstract_model.cc:1404] Engine \"RandomForestGeneric\" built\n",
      "2025-01-28 11:18:38.277460: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1035] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9804\n",
      "Validation Accuracy: 0.9803686141967773\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9800\n",
      "Test Accuracy: 0.9799812436103821\n",
      "132/132 [==============================] - 0s 1ms/step\n",
      "\n",
      "Classification Report on Test Dataset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Failure       1.00      0.99      0.99     80817\n",
      "      Normal       0.85      1.00      0.92     10865\n",
      "     Warning       0.98      0.96      0.97     42542\n",
      "\n",
      "    accuracy                           0.98    134224\n",
      "   macro avg       0.94      0.98      0.96    134224\n",
      "weighted avg       0.98      0.98      0.98    134224\n",
      "\n",
      "\n",
      "Confusion Matrix on Test Dataset:\n",
      "[[79889   217   711]\n",
      " [    0 10865     0]\n",
      " [    0  1759 40783]]\n",
      "\n",
      "Training with feature set: With Power Consumption and Downtime\n",
      "Use /var/folders/4t/vgrmglh57ds018mbdc9875y80000gn/T/tmp8dvsbhcr as temporary training directory\n",
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.492359. Found 429513 examples.\n",
      "Reading validation dataset...\n",
      "Num validation examples: tf.Tensor(107379, shape=(), dtype=int32)\n",
      "Validation dataset read in 0:00:00.182065. Found 107379 examples.\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1738059520.043756 1330287 kernel.cc:782] Start Yggdrasil model training\n",
      "I0000 00:00:1738059520.043767 1330287 kernel.cc:783] Collect training examples\n",
      "I0000 00:00:1738059520.043771 1330287 kernel.cc:795] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1738059520.043814 1330287 kernel.cc:401] Number of batches: 420\n",
      "I0000 00:00:1738059520.043817 1330287 kernel.cc:402] Number of examples: 429513\n",
      "I0000 00:00:1738059520.067809 1330287 kernel.cc:802] Training dataset:\n",
      "Number of records: 429513\n",
      "Number of columns: 8\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 7 (87.5%)\n",
      "\tCATEGORICAL: 1 (12.5%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 7 (87.5%)\n",
      "\t1: \"__WEIGHTS\" NUMERICAL mean:0.999494 min:0.553534 max:4.12163 sd:0.952719\n",
      "\t2: \"data:0.0\" NUMERICAL mean:14.9895 min:0 max:30 sd:8.6562\n",
      "\t3: \"data:0.1\" NUMERICAL mean:49.6553 min:-51.31 max:100 sd:19.5554\n",
      "\t4: \"data:0.2\" NUMERICAL mean:449.72 min:100 max:800 sd:201.913\n",
      "\t5: \"data:0.3\" NUMERICAL mean:50.0138 min:-17.72 max:122.11 sd:15.0098\n",
      "\t6: \"data:0.4\" NUMERICAL mean:999.42 min:33.96 max:1956.02 sd:199.622\n",
      "\t7: \"data:0.5\" NUMERICAL mean:11.9988 min:0 max:24 sd:6.92757\n",
      "\n",
      "CATEGORICAL: 1 (12.5%)\n",
      "\t0: \"__LABEL\" CATEGORICAL integerized vocab-size:4 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1738059520.067835 1330287 kernel.cc:807] Collect validation dataset\n",
      "I0000 00:00:1738059520.067867 1330287 kernel.cc:401] Number of batches: 105\n",
      "I0000 00:00:1738059520.067874 1330287 kernel.cc:402] Number of examples: 107379\n",
      "I0000 00:00:1738059520.074061 1330287 kernel.cc:813] Validation dataset:\n",
      "Number of records: 107379\n",
      "Number of columns: 8\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 7 (87.5%)\n",
      "\tCATEGORICAL: 1 (12.5%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 7 (87.5%)\n",
      "\t1: \"__WEIGHTS\" NUMERICAL mean:1.00169 min:0.553534 max:4.12163 sd:0.955654\n",
      "\t2: \"data:0.0\" NUMERICAL mean:14.9985 min:0 max:30 sd:8.67014\n",
      "\t3: \"data:0.1\" NUMERICAL mean:49.6671 min:-37.57 max:100 sd:19.5567\n",
      "\t4: \"data:0.2\" NUMERICAL mean:449.234 min:100.01 max:800 sd:202.216\n",
      "\t5: \"data:0.3\" NUMERICAL mean:49.9831 min:-13.24 max:113.16 sd:15.0208\n",
      "\t6: \"data:0.4\" NUMERICAL mean:1000.45 min:164.41 max:2055.84 sd:201.011\n",
      "\t7: \"data:0.5\" NUMERICAL mean:11.9907 min:0 max:24 sd:6.93704\n",
      "\n",
      "CATEGORICAL: 1 (12.5%)\n",
      "\t0: \"__LABEL\" CATEGORICAL integerized vocab-size:4 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1738059520.074085 1330287 kernel.cc:818] Configure learner\n",
      "I0000 00:00:1738059520.074270 1330287 kernel.cc:831] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^data:0\\\\.0$\"\n",
      "features: \"^data:0\\\\.1$\"\n",
      "features: \"^data:0\\\\.2$\"\n",
      "features: \"^data:0\\\\.3$\"\n",
      "features: \"^data:0\\\\.4$\"\n",
      "features: \"^data:0\\\\.5$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "weight_definition {\n",
      "  attribute: \"__WEIGHTS\"\n",
      "  numerical {\n",
      "  }\n",
      "}\n",
      "random_seed: 42\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 50\n",
      "  decision_tree {\n",
      "    max_depth: 7\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1738059520.074307 1330287 kernel.cc:834] Deployment config:\n",
      "cache_path: \"/var/folders/4t/vgrmglh57ds018mbdc9875y80000gn/T/tmp8dvsbhcr/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1738059520.074391 1333641 kernel.cc:895] Train model\n",
      "I0000 00:00:1738059520.074433 1333641 random_forest.cc:427] Training random forest on 429513 example(s) and 6 feature(s).\n",
      "I0000 00:00:1738059520.415498 1333648 random_forest.cc:811] Training of tree  1/50 (tree index:3) done accuracy:0.98298 logloss:0.61346\n",
      "I0000 00:00:1738059520.790695 1333655 random_forest.cc:811] Training of tree  11/50 (tree index:9) done accuracy:0.981918 logloss:0.640277\n",
      "I0000 00:00:1738059521.190026 1333652 random_forest.cc:811] Training of tree  21/50 (tree index:20) done accuracy:0.981911 logloss:0.636516\n",
      "I0000 00:00:1738059521.597836 1333654 random_forest.cc:811] Training of tree  31/50 (tree index:29) done accuracy:0.982565 logloss:0.634082\n",
      "I0000 00:00:1738059521.979130 1333654 random_forest.cc:811] Training of tree  41/50 (tree index:38) done accuracy:0.982673 logloss:0.632173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained in 0:00:02.202203\n",
      "Compiling model...\n",
      "Model compiled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1738059522.234242 1333651 random_forest.cc:811] Training of tree  50/50 (tree index:49) done accuracy:0.982672 logloss:0.632374\n",
      "I0000 00:00:1738059522.234334 1333641 random_forest.cc:891] Final OOB metrics: accuracy:0.982672 logloss:0.632374\n",
      "I0000 00:00:1738059522.235860 1333641 kernel.cc:926] Export model in log directory: /var/folders/4t/vgrmglh57ds018mbdc9875y80000gn/T/tmp8dvsbhcr with prefix 4404d1320713432c\n",
      "I0000 00:00:1738059522.237027 1333641 kernel.cc:944] Save model in resources\n",
      "I0000 00:00:1738059522.239043 1330287 abstract_model.cc:914] Model self evaluation:\n",
      "Number of predictions (without weights): 429513\n",
      "Number of predictions (with weights): 429296\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.982672  CI95[W][0.982341 0.982998]\n",
      "LogLoss: : 0.632374\n",
      "ErrorRate: : 0.017328\n",
      "\n",
      "Default Accuracy: : 0.333599\n",
      "Default LogLoss: : 1.09861\n",
      "Default ErrorRate: : 0.666401\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "                   1                  2                  3\n",
      "1  141647.7589194775  372.5285632610321  1192.312816143036\n",
      "2                  0   142929.726433754                  0\n",
      "3                  0     5873.974173069  137279.5618467331\n",
      "Total: 429295.8627524376\n",
      "\n",
      "\n",
      "2025-01-28 11:18:42.242000: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1206] Loading model from path /var/folders/4t/vgrmglh57ds018mbdc9875y80000gn/T/tmp8dvsbhcr/model/ with prefix 4404d1320713432c\n",
      "I0000 00:00:1738059522.244378 1330287 decision_forest.cc:761] Model loaded with 50 root(s), 1792 node(s), and 6 input feature(s).\n",
      "2025-01-28 11:18:42.244390: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1035] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9804\n",
      "Validation Accuracy: 0.9803686141967773\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9800\n",
      "Test Accuracy: 0.9799812436103821\n",
      "132/132 [==============================] - 0s 1ms/step\n",
      "\n",
      "Classification Report on Test Dataset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Failure       1.00      0.99      0.99     80817\n",
      "      Normal       0.85      1.00      0.92     10865\n",
      "     Warning       0.98      0.96      0.97     42542\n",
      "\n",
      "    accuracy                           0.98    134224\n",
      "   macro avg       0.94      0.98      0.96    134224\n",
      "weighted avg       0.98      0.98      0.98    134224\n",
      "\n",
      "\n",
      "Confusion Matrix on Test Dataset:\n",
      "[[79889   217   711]\n",
      " [    0 10865     0]\n",
      " [    0  1759 40783]]\n",
      "\n",
      "Training with feature set: With Humidity\n",
      "Use /var/folders/4t/vgrmglh57ds018mbdc9875y80000gn/T/tmp_3yl_w51 as temporary training directory\n",
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.486068. Found 429513 examples.\n",
      "Reading validation dataset...\n",
      "Num validation examples: tf.Tensor(107379, shape=(), dtype=int32)\n",
      "Validation dataset read in 0:00:00.186834. Found 107379 examples.\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1738059524.030115 1330287 kernel.cc:782] Start Yggdrasil model training\n",
      "I0000 00:00:1738059524.030124 1330287 kernel.cc:783] Collect training examples\n",
      "I0000 00:00:1738059524.030128 1330287 kernel.cc:795] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1738059524.030181 1330287 kernel.cc:401] Number of batches: 420\n",
      "I0000 00:00:1738059524.030184 1330287 kernel.cc:402] Number of examples: 429513\n",
      "I0000 00:00:1738059524.051301 1330287 kernel.cc:802] Training dataset:\n",
      "Number of records: 429513\n",
      "Number of columns: 7\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 6 (85.7143%)\n",
      "\tCATEGORICAL: 1 (14.2857%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 6 (85.7143%)\n",
      "\t1: \"__WEIGHTS\" NUMERICAL mean:0.999494 min:0.553534 max:4.12163 sd:0.952719\n",
      "\t2: \"data:0.0\" NUMERICAL mean:14.9895 min:0 max:30 sd:8.6562\n",
      "\t3: \"data:0.1\" NUMERICAL mean:49.6553 min:-51.31 max:100 sd:19.5554\n",
      "\t4: \"data:0.2\" NUMERICAL mean:449.72 min:100 max:800 sd:201.913\n",
      "\t5: \"data:0.3\" NUMERICAL mean:50.0138 min:-17.72 max:122.11 sd:15.0098\n",
      "\t6: \"data:0.4\" NUMERICAL mean:49.9957 min:-0 max:100 sd:19.0737\n",
      "\n",
      "CATEGORICAL: 1 (14.2857%)\n",
      "\t0: \"__LABEL\" CATEGORICAL integerized vocab-size:4 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1738059524.051328 1330287 kernel.cc:807] Collect validation dataset\n",
      "I0000 00:00:1738059524.051360 1330287 kernel.cc:401] Number of batches: 105\n",
      "I0000 00:00:1738059524.051363 1330287 kernel.cc:402] Number of examples: 107379\n",
      "I0000 00:00:1738059524.056583 1330287 kernel.cc:813] Validation dataset:\n",
      "Number of records: 107379\n",
      "Number of columns: 7\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 6 (85.7143%)\n",
      "\tCATEGORICAL: 1 (14.2857%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 6 (85.7143%)\n",
      "\t1: \"__WEIGHTS\" NUMERICAL mean:1.00169 min:0.553534 max:4.12163 sd:0.955654\n",
      "\t2: \"data:0.0\" NUMERICAL mean:14.9985 min:0 max:30 sd:8.67014\n",
      "\t3: \"data:0.1\" NUMERICAL mean:49.6671 min:-37.57 max:100 sd:19.5567\n",
      "\t4: \"data:0.2\" NUMERICAL mean:449.234 min:100.01 max:800 sd:202.216\n",
      "\t5: \"data:0.3\" NUMERICAL mean:49.9831 min:-13.24 max:113.16 sd:15.0208\n",
      "\t6: \"data:0.4\" NUMERICAL mean:49.9184 min:0 max:99.99 sd:19.1136\n",
      "\n",
      "CATEGORICAL: 1 (14.2857%)\n",
      "\t0: \"__LABEL\" CATEGORICAL integerized vocab-size:4 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1738059524.056603 1330287 kernel.cc:818] Configure learner\n",
      "I0000 00:00:1738059524.056739 1330287 kernel.cc:831] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^data:0\\\\.0$\"\n",
      "features: \"^data:0\\\\.1$\"\n",
      "features: \"^data:0\\\\.2$\"\n",
      "features: \"^data:0\\\\.3$\"\n",
      "features: \"^data:0\\\\.4$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "weight_definition {\n",
      "  attribute: \"__WEIGHTS\"\n",
      "  numerical {\n",
      "  }\n",
      "}\n",
      "random_seed: 42\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 50\n",
      "  decision_tree {\n",
      "    max_depth: 7\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1738059524.056821 1330287 kernel.cc:834] Deployment config:\n",
      "cache_path: \"/var/folders/4t/vgrmglh57ds018mbdc9875y80000gn/T/tmp_3yl_w51/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1738059524.056933 1333815 kernel.cc:895] Train model\n",
      "I0000 00:00:1738059524.057088 1333815 random_forest.cc:427] Training random forest on 429513 example(s) and 5 feature(s).\n",
      "I0000 00:00:1738059524.386187 1333823 random_forest.cc:811] Training of tree  1/50 (tree index:4) done accuracy:0.999125 logloss:0.0315333\n",
      "I0000 00:00:1738059524.734374 1333824 random_forest.cc:811] Training of tree  11/50 (tree index:13) done accuracy:0.998892 logloss:0.0151636\n",
      "I0000 00:00:1738059525.078293 1333822 random_forest.cc:811] Training of tree  21/50 (tree index:20) done accuracy:0.999861 logloss:0.004651\n",
      "I0000 00:00:1738059525.448133 1333827 random_forest.cc:811] Training of tree  31/50 (tree index:30) done accuracy:0.999951 logloss:0.0037806\n",
      "I0000 00:00:1738059525.819173 1333821 random_forest.cc:811] Training of tree  41/50 (tree index:39) done accuracy:0.999965 logloss:0.00404049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained in 0:00:02.046539\n",
      "Compiling model...\n",
      "Model compiled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1738059526.065278 1333826 random_forest.cc:811] Training of tree  50/50 (tree index:49) done accuracy:0.999974 logloss:0.00452913\n",
      "I0000 00:00:1738059526.065351 1333815 random_forest.cc:891] Final OOB metrics: accuracy:0.999974 logloss:0.00452913\n",
      "I0000 00:00:1738059526.066857 1333815 kernel.cc:926] Export model in log directory: /var/folders/4t/vgrmglh57ds018mbdc9875y80000gn/T/tmp_3yl_w51 with prefix b161877bf15f4d92\n",
      "I0000 00:00:1738059526.068026 1333815 kernel.cc:944] Save model in resources\n",
      "I0000 00:00:1738059526.069315 1330287 abstract_model.cc:914] Model self evaluation:\n",
      "Number of predictions (without weights): 429513\n",
      "Number of predictions (with weights): 429296\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.999974  CI95[W][0.999957 0.999985]\n",
      "LogLoss: : 0.00452913\n",
      "ErrorRate: : 2.58088e-05\n",
      "\n",
      "Default Accuracy: : 0.333599\n",
      "Default LogLoss: : 1.09861\n",
      "Default ErrorRate: : 0.666401\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "                   1                 2                  3\n",
      "1  143201.5296134949                 0  11.07068538665771\n",
      "2                  0  142929.726433754                  0\n",
      "3                  0                 0  143153.5360198021\n",
      "Total: 429295.8627524376\n",
      "\n",
      "\n",
      "2025-01-28 11:18:46.072430: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1206] Loading model from path /var/folders/4t/vgrmglh57ds018mbdc9875y80000gn/T/tmp_3yl_w51/model/ with prefix b161877bf15f4d92\n",
      "I0000 00:00:1738059526.074911 1330287 decision_forest.cc:761] Model loaded with 50 root(s), 1590 node(s), and 5 input feature(s).\n",
      "2025-01-28 11:18:46.074985: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1035] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Validation Accuracy: 0.9999720454216003\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Test Accuracy: 0.9999925494194031\n",
      "132/132 [==============================] - 0s 1ms/step\n",
      "\n",
      "Classification Report on Test Dataset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Failure       1.00      1.00      1.00     80817\n",
      "      Normal       1.00      1.00      1.00     10865\n",
      "     Warning       1.00      1.00      1.00     42542\n",
      "\n",
      "    accuracy                           1.00    134224\n",
      "   macro avg       1.00      1.00      1.00    134224\n",
      "weighted avg       1.00      1.00      1.00    134224\n",
      "\n",
      "\n",
      "Confusion Matrix on Test Dataset:\n",
      "[[80816     0     1]\n",
      " [    0 10865     0]\n",
      " [    0     0 42542]]\n",
      "\n",
      "Training with feature set: With All Features\n",
      "Use /var/folders/4t/vgrmglh57ds018mbdc9875y80000gn/T/tmphl_y3o9p as temporary training directory\n",
      "Reading training dataset...\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function CoreModel._consumes_training_examples_until_eof at 0x17532d3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function CoreModel._consumes_training_examples_until_eof at 0x17532d3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset read in 0:00:00.509909. Found 429513 examples.\n",
      "Reading validation dataset...\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function CoreModel._consumes_validation_examples_until_eof at 0x17532d580> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function CoreModel._consumes_validation_examples_until_eof at 0x17532d580> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num validation examples: tf.Tensor(107379, shape=(), dtype=int32)\n",
      "Validation dataset read in 0:00:00.196453. Found 107379 examples.\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1738059527.854149 1330287 kernel.cc:782] Start Yggdrasil model training\n",
      "I0000 00:00:1738059527.854160 1330287 kernel.cc:783] Collect training examples\n",
      "I0000 00:00:1738059527.854165 1330287 kernel.cc:795] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1738059527.854205 1330287 kernel.cc:401] Number of batches: 420\n",
      "I0000 00:00:1738059527.854208 1330287 kernel.cc:402] Number of examples: 429513\n",
      "I0000 00:00:1738059527.883131 1330287 kernel.cc:802] Training dataset:\n",
      "Number of records: 429513\n",
      "Number of columns: 9\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 8 (88.8889%)\n",
      "\tCATEGORICAL: 1 (11.1111%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 8 (88.8889%)\n",
      "\t1: \"__WEIGHTS\" NUMERICAL mean:0.999494 min:0.553534 max:4.12163 sd:0.952719\n",
      "\t2: \"data:0.0\" NUMERICAL mean:14.9895 min:0 max:30 sd:8.6562\n",
      "\t3: \"data:0.1\" NUMERICAL mean:49.6553 min:-51.31 max:100 sd:19.5554\n",
      "\t4: \"data:0.2\" NUMERICAL mean:449.72 min:100 max:800 sd:201.913\n",
      "\t5: \"data:0.3\" NUMERICAL mean:50.0138 min:-17.72 max:122.11 sd:15.0098\n",
      "\t6: \"data:0.4\" NUMERICAL mean:999.42 min:33.96 max:1956.02 sd:199.622\n",
      "\t7: \"data:0.5\" NUMERICAL mean:11.9988 min:0 max:24 sd:6.92757\n",
      "\t8: \"data:0.6\" NUMERICAL mean:49.9957 min:-0 max:100 sd:19.0737\n",
      "\n",
      "CATEGORICAL: 1 (11.1111%)\n",
      "\t0: \"__LABEL\" CATEGORICAL integerized vocab-size:4 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1738059527.883155 1330287 kernel.cc:807] Collect validation dataset\n",
      "I0000 00:00:1738059527.883188 1330287 kernel.cc:401] Number of batches: 105\n",
      "I0000 00:00:1738059527.883192 1330287 kernel.cc:402] Number of examples: 107379\n",
      "I0000 00:00:1738059527.890117 1330287 kernel.cc:813] Validation dataset:\n",
      "Number of records: 107379\n",
      "Number of columns: 9\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 8 (88.8889%)\n",
      "\tCATEGORICAL: 1 (11.1111%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 8 (88.8889%)\n",
      "\t1: \"__WEIGHTS\" NUMERICAL mean:1.00169 min:0.553534 max:4.12163 sd:0.955654\n",
      "\t2: \"data:0.0\" NUMERICAL mean:14.9985 min:0 max:30 sd:8.67014\n",
      "\t3: \"data:0.1\" NUMERICAL mean:49.6671 min:-37.57 max:100 sd:19.5567\n",
      "\t4: \"data:0.2\" NUMERICAL mean:449.234 min:100.01 max:800 sd:202.216\n",
      "\t5: \"data:0.3\" NUMERICAL mean:49.9831 min:-13.24 max:113.16 sd:15.0208\n",
      "\t6: \"data:0.4\" NUMERICAL mean:1000.45 min:164.41 max:2055.84 sd:201.011\n",
      "\t7: \"data:0.5\" NUMERICAL mean:11.9907 min:0 max:24 sd:6.93704\n",
      "\t8: \"data:0.6\" NUMERICAL mean:49.9184 min:0 max:99.99 sd:19.1136\n",
      "\n",
      "CATEGORICAL: 1 (11.1111%)\n",
      "\t0: \"__LABEL\" CATEGORICAL integerized vocab-size:4 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1738059527.890137 1330287 kernel.cc:818] Configure learner\n",
      "I0000 00:00:1738059527.890267 1330287 kernel.cc:831] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^data:0\\\\.0$\"\n",
      "features: \"^data:0\\\\.1$\"\n",
      "features: \"^data:0\\\\.2$\"\n",
      "features: \"^data:0\\\\.3$\"\n",
      "features: \"^data:0\\\\.4$\"\n",
      "features: \"^data:0\\\\.5$\"\n",
      "features: \"^data:0\\\\.6$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "weight_definition {\n",
      "  attribute: \"__WEIGHTS\"\n",
      "  numerical {\n",
      "  }\n",
      "}\n",
      "random_seed: 42\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 50\n",
      "  decision_tree {\n",
      "    max_depth: 7\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1738059527.890295 1330287 kernel.cc:834] Deployment config:\n",
      "cache_path: \"/var/folders/4t/vgrmglh57ds018mbdc9875y80000gn/T/tmphl_y3o9p/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1738059527.890362 1333979 kernel.cc:895] Train model\n",
      "I0000 00:00:1738059527.890407 1333979 random_forest.cc:427] Training random forest on 429513 example(s) and 7 feature(s).\n",
      "I0000 00:00:1738059528.225891 1333990 random_forest.cc:811] Training of tree  1/50 (tree index:3) done accuracy:0.984203 logloss:0.569376\n",
      "I0000 00:00:1738059528.553321 1333993 random_forest.cc:811] Training of tree  11/50 (tree index:11) done accuracy:0.994973 logloss:0.0548303\n",
      "I0000 00:00:1738059528.959734 1333991 random_forest.cc:811] Training of tree  21/50 (tree index:21) done accuracy:0.998284 logloss:0.0235602\n",
      "I0000 00:00:1738059529.313891 1333987 random_forest.cc:811] Training of tree  31/50 (tree index:31) done accuracy:0.998959 logloss:0.019412\n",
      "I0000 00:00:1738059529.734020 1333993 random_forest.cc:811] Training of tree  41/50 (tree index:41) done accuracy:0.999038 logloss:0.0217985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained in 0:00:02.190994\n",
      "Compiling model...\n",
      "Model compiled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1738059530.033342 1333993 random_forest.cc:811] Training of tree  50/50 (tree index:48) done accuracy:0.999304 logloss:0.0219263\n",
      "I0000 00:00:1738059530.033563 1333979 random_forest.cc:891] Final OOB metrics: accuracy:0.999304 logloss:0.0219263\n",
      "I0000 00:00:1738059530.035426 1333979 kernel.cc:926] Export model in log directory: /var/folders/4t/vgrmglh57ds018mbdc9875y80000gn/T/tmphl_y3o9p with prefix f8e450ac52274d88\n",
      "I0000 00:00:1738059530.036549 1333979 kernel.cc:944] Save model in resources\n",
      "I0000 00:00:1738059530.038171 1330287 abstract_model.cc:914] Model self evaluation:\n",
      "Number of predictions (without weights): 429513\n",
      "Number of predictions (with weights): 429296\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.999304  CI95[W][0.999234 0.999369]\n",
      "LogLoss: : 0.0219263\n",
      "ErrorRate: : 0.000696123\n",
      "\n",
      "Default Accuracy: : 0.333599\n",
      "Default LogLoss: : 1.09861\n",
      "Default ErrorRate: : 0.666401\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "                   1                 2                  3\n",
      "1  142914.7988619804                 0  297.8014369010925\n",
      "2                  0  142929.726433754                  0\n",
      "3  1.051741123199463                 0  143152.4842786789\n",
      "Total: 429295.8627524376\n",
      "\n",
      "\n",
      "2025-01-28 11:18:50.041240: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1206] Loading model from path /var/folders/4t/vgrmglh57ds018mbdc9875y80000gn/T/tmphl_y3o9p/model/ with prefix f8e450ac52274d88\n",
      "I0000 00:00:1738059530.043524 1330287 decision_forest.cc:761] Model loaded with 50 root(s), 1702 node(s), and 7 input feature(s).\n",
      "I0000 00:00:1738059530.043532 1330287 abstract_model.cc:1404] Engine \"RandomForestGeneric\" built\n",
      "2025-01-28 11:18:50.043536: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1035] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9985\n",
      "Validation Accuracy: 0.998500645160675\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9984\n",
      "Test Accuracy: 0.9983832836151123\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "\n",
      "Classification Report on Test Dataset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Failure       1.00      1.00      1.00     80817\n",
      "      Normal       1.00      1.00      1.00     10865\n",
      "     Warning       0.99      1.00      1.00     42542\n",
      "\n",
      "    accuracy                           1.00    134224\n",
      "   macro avg       1.00      1.00      1.00    134224\n",
      "weighted avg       1.00      1.00      1.00    134224\n",
      "\n",
      "\n",
      "Confusion Matrix on Test Dataset:\n",
      "[[80600     0   217]\n",
      " [    0 10865     0]\n",
      " [    0     0 42542]]\n",
      "\n",
      "Feature Set Comparison Results:\n",
      "Base Features:\n",
      "  Validation Accuracy: 0.9804\n",
      "  Test Accuracy: 0.9800\n",
      "With Power Consumption and Downtime:\n",
      "  Validation Accuracy: 0.9804\n",
      "  Test Accuracy: 0.9800\n",
      "With Humidity:\n",
      "  Validation Accuracy: 1.0000\n",
      "  Test Accuracy: 1.0000\n",
      "With All Features:\n",
      "  Validation Accuracy: 0.9985\n",
      "  Test Accuracy: 0.9984\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_decision_forests as tfdf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# TPU/GPU Strategy setup\n",
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n",
    "    strategy = tf.distribute.TPUStrategy(tpu)\n",
    "    print(\"Running on TPU:\", tpu.master())\n",
    "except ValueError:\n",
    "    print(\"TPU not found. Running on CPU/GPU.\")\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "class RandomForestClassifier:\n",
    "    def __init__(self, data_path):\n",
    "        self.df = pd.read_csv(data_path)\n",
    "        self.preprocess_data()\n",
    "        self.setup_class_weights()\n",
    "        \n",
    "    def preprocess_data(self):\n",
    "        \"\"\"Preprocess the data by encoding categorical variables\"\"\"\n",
    "        self.df['Status'] = LabelEncoder().fit_transform(self.df['Status'])\n",
    "        self.df['Firmware_Version'] = LabelEncoder().fit_transform(self.df['Firmware_Version'])\n",
    "        self.df['Antenna_ID'] = LabelEncoder().fit_transform(self.df['Antenna_ID'])\n",
    "        \n",
    "    def setup_class_weights(self):\n",
    "        \"\"\"Calculate class weights for imbalanced dataset\"\"\"\n",
    "        self.class_weights = compute_class_weight('balanced', \n",
    "                                                classes=np.unique(self.df['Status']), \n",
    "                                                y=self.df['Status'])\n",
    "        self.class_weights_dict = {i: weight for i, weight in enumerate(self.class_weights)}\n",
    "        print(\"Class Weights:\", self.class_weights_dict)\n",
    "        \n",
    "    def convert_to_tf_dataset(self, X, y):\n",
    "        \"\"\"Convert data to TensorFlow dataset\"\"\"\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((X.values, y.values))\n",
    "        dataset = dataset.batch(1024)\n",
    "        return dataset\n",
    "    \n",
    "    def prepare_data(self, features, target='Status'):\n",
    "        \"\"\"Prepare train, validation, and test datasets\"\"\"\n",
    "        X = self.df[features]\n",
    "        y = self.df[target]\n",
    "        \n",
    "        # First split: train+val / test\n",
    "        X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42\n",
    "        )\n",
    "        \n",
    "        # Second split: train / val\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X_train_val, y_train_val, test_size=0.2, random_state=42\n",
    "        )\n",
    "        \n",
    "        # Convert to TF datasets\n",
    "        train_dataset = self.convert_to_tf_dataset(X_train, y_train)\n",
    "        val_dataset = self.convert_to_tf_dataset(X_val, y_val)\n",
    "        test_dataset = self.convert_to_tf_dataset(X_test, y_test)\n",
    "        \n",
    "        return train_dataset, val_dataset, test_dataset, y_test.values\n",
    "    \n",
    "    def train_and_evaluate_rf(self, train_dataset, val_dataset, test_dataset, y_test):\n",
    "        \"\"\"Train and evaluate the random forest model\"\"\"\n",
    "        with strategy.scope():\n",
    "            model = tfdf.keras.RandomForestModel(\n",
    "                num_trees=50,\n",
    "                max_depth=7,\n",
    "                min_examples=10,\n",
    "                task=tfdf.keras.Task.CLASSIFICATION,\n",
    "                random_seed=42\n",
    "            )\n",
    "            model.compile(metrics=[\"accuracy\"])\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(train_dataset, validation_data=val_dataset, \n",
    "                 class_weight=self.class_weights_dict, verbose=1)\n",
    "        \n",
    "        # Evaluate on validation set\n",
    "        val_evaluation = model.evaluate(val_dataset, return_dict=True)\n",
    "        print(\"Validation Accuracy:\", val_evaluation[\"accuracy\"])\n",
    "        \n",
    "        # Evaluate on test set\n",
    "        test_evaluation = model.evaluate(test_dataset, return_dict=True)\n",
    "        print(\"Test Accuracy:\", test_evaluation[\"accuracy\"])\n",
    "        \n",
    "        # Generate predictions\n",
    "        y_pred = model.predict(test_dataset)\n",
    "        y_pred = np.argmax(y_pred, axis=1)\n",
    "        \n",
    "        # Print classification report\n",
    "        print(\"\\nClassification Report on Test Dataset:\")\n",
    "        print(classification_report(y_test, y_pred, \n",
    "                                 target_names=['Failure', 'Normal', 'Warning']))\n",
    "        \n",
    "        # Print confusion matrix\n",
    "        print(\"\\nConfusion Matrix on Test Dataset:\")\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "        \n",
    "        return val_evaluation[\"accuracy\"], test_evaluation[\"accuracy\"]\n",
    "    \n",
    "    def compare_feature_sets(self, feature_sets):\n",
    "        \"\"\"Compare different feature sets\"\"\"\n",
    "        results = {}\n",
    "        for key, features in feature_sets.items():\n",
    "            print(f\"\\nTraining with feature set: {key}\")\n",
    "            train_ds, val_ds, test_ds, y_test = self.prepare_data(features)\n",
    "            val_acc, test_acc = self.train_and_evaluate_rf(\n",
    "                train_ds, val_ds, test_ds, y_test\n",
    "            )\n",
    "            results[key] = {\n",
    "                'Validation Accuracy': val_acc, \n",
    "                'Test Accuracy': test_acc\n",
    "            }\n",
    "        return results\n",
    "\n",
    "# Define feature sets\n",
    "features_base = ['SINR', 'Signal_Strength', 'Traffic', 'Temperature']\n",
    "features_with_power_downtime = features_base + ['Power_Consumption', 'Downtime']\n",
    "features_with_humidity = features_base + ['Humidity']\n",
    "features_all = features_base + ['Power_Consumption', 'Downtime', 'Humidity']\n",
    "\n",
    "feature_sets = {\n",
    "    \"Base Features\": features_base,\n",
    "    \"With Power Consumption and Downtime\": features_with_power_downtime,\n",
    "    \"With Humidity\": features_with_humidity,\n",
    "    \"With All Features\": features_all\n",
    "}\n",
    "\n",
    "# Usage example\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize classifier\n",
    "    rf_classifier = RandomForestClassifier(\"../mobilis_data_cleaned.csv\")\n",
    "    \n",
    "    # Compare feature sets\n",
    "    print(\"\\nComparing feature sets...\")\n",
    "    results = rf_classifier.compare_feature_sets(feature_sets)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\nFeature Set Comparison Results:\")\n",
    "    for feature_set, metrics in results.items():\n",
    "        print(f\"{feature_set}:\")\n",
    "        print(f\"  Validation Accuracy: {metrics['Validation Accuracy']:.4f}\")\n",
    "        print(f\"  Test Accuracy: {metrics['Test Accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use /var/folders/4t/vgrmglh57ds018mbdc9875y80000gn/T/tmpv3knixu4 as temporary training directory\n",
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.551546. Found 429513 examples.\n",
      "Reading validation dataset...\n",
      "Num validation examples: tf.Tensor(107379, shape=(), dtype=int32)\n",
      "Validation dataset read in 0:00:00.183959. Found 107379 examples.\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1738060207.201089 1330287 kernel.cc:782] Start Yggdrasil model training\n",
      "I0000 00:00:1738060207.202079 1330287 kernel.cc:783] Collect training examples\n",
      "I0000 00:00:1738060207.202087 1330287 kernel.cc:795] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1738060207.203830 1330287 kernel.cc:401] Number of batches: 420\n",
      "I0000 00:00:1738060207.203836 1330287 kernel.cc:402] Number of examples: 429513\n",
      "I0000 00:00:1738060207.225861 1330287 kernel.cc:802] Training dataset:\n",
      "Number of records: 429513\n",
      "Number of columns: 7\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 6 (85.7143%)\n",
      "\tCATEGORICAL: 1 (14.2857%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 6 (85.7143%)\n",
      "\t1: \"__WEIGHTS\" NUMERICAL mean:0.999494 min:0.553534 max:4.12163 sd:0.952719\n",
      "\t2: \"data:0.0\" NUMERICAL mean:14.9895 min:0 max:30 sd:8.6562\n",
      "\t3: \"data:0.1\" NUMERICAL mean:49.6553 min:-51.31 max:100 sd:19.5554\n",
      "\t4: \"data:0.2\" NUMERICAL mean:449.72 min:100 max:800 sd:201.913\n",
      "\t5: \"data:0.3\" NUMERICAL mean:50.0138 min:-17.72 max:122.11 sd:15.0098\n",
      "\t6: \"data:0.4\" NUMERICAL mean:49.9957 min:-0 max:100 sd:19.0737\n",
      "\n",
      "CATEGORICAL: 1 (14.2857%)\n",
      "\t0: \"__LABEL\" CATEGORICAL integerized vocab-size:4 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1738060207.225914 1330287 kernel.cc:807] Collect validation dataset\n",
      "I0000 00:00:1738060207.225941 1330287 kernel.cc:401] Number of batches: 105\n",
      "I0000 00:00:1738060207.225945 1330287 kernel.cc:402] Number of examples: 107379\n",
      "I0000 00:00:1738060207.231317 1330287 kernel.cc:813] Validation dataset:\n",
      "Number of records: 107379\n",
      "Number of columns: 7\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 6 (85.7143%)\n",
      "\tCATEGORICAL: 1 (14.2857%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 6 (85.7143%)\n",
      "\t1: \"__WEIGHTS\" NUMERICAL mean:1.00169 min:0.553534 max:4.12163 sd:0.955654\n",
      "\t2: \"data:0.0\" NUMERICAL mean:14.9985 min:0 max:30 sd:8.67014\n",
      "\t3: \"data:0.1\" NUMERICAL mean:49.6671 min:-37.57 max:100 sd:19.5567\n",
      "\t4: \"data:0.2\" NUMERICAL mean:449.234 min:100.01 max:800 sd:202.216\n",
      "\t5: \"data:0.3\" NUMERICAL mean:49.9831 min:-13.24 max:113.16 sd:15.0208\n",
      "\t6: \"data:0.4\" NUMERICAL mean:49.9184 min:0 max:99.99 sd:19.1136\n",
      "\n",
      "CATEGORICAL: 1 (14.2857%)\n",
      "\t0: \"__LABEL\" CATEGORICAL integerized vocab-size:4 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1738060207.231338 1330287 kernel.cc:818] Configure learner\n",
      "I0000 00:00:1738060207.231679 1330287 kernel.cc:831] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^data:0\\\\.0$\"\n",
      "features: \"^data:0\\\\.1$\"\n",
      "features: \"^data:0\\\\.2$\"\n",
      "features: \"^data:0\\\\.3$\"\n",
      "features: \"^data:0\\\\.4$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "weight_definition {\n",
      "  attribute: \"__WEIGHTS\"\n",
      "  numerical {\n",
      "  }\n",
      "}\n",
      "random_seed: 42\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 50\n",
      "  decision_tree {\n",
      "    max_depth: 7\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1738060207.231896 1330287 kernel.cc:834] Deployment config:\n",
      "cache_path: \"/var/folders/4t/vgrmglh57ds018mbdc9875y80000gn/T/tmpv3knixu4/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1738060207.231996 1346389 kernel.cc:895] Train model\n",
      "I0000 00:00:1738060207.232649 1346389 random_forest.cc:427] Training random forest on 429513 example(s) and 5 feature(s).\n",
      "I0000 00:00:1738060207.532852 1346395 random_forest.cc:811] Training of tree  1/50 (tree index:0) done accuracy:0.967923 logloss:1.15618\n",
      "I0000 00:00:1738060207.894295 1346397 random_forest.cc:811] Training of tree  11/50 (tree index:10) done accuracy:0.998916 logloss:0.0145555\n",
      "I0000 00:00:1738060208.231840 1346396 random_forest.cc:811] Training of tree  21/50 (tree index:20) done accuracy:0.999861 logloss:0.004651\n",
      "I0000 00:00:1738060208.618917 1346398 random_forest.cc:811] Training of tree  31/50 (tree index:30) done accuracy:0.999951 logloss:0.0037806\n",
      "I0000 00:00:1738060209.012922 1346400 random_forest.cc:811] Training of tree  41/50 (tree index:42) done accuracy:0.999956 logloss:0.00409616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained in 0:00:02.078005\n",
      "Compiling model...\n",
      "Model compiled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1738060209.251812 1346397 random_forest.cc:811] Training of tree  50/50 (tree index:49) done accuracy:0.999974 logloss:0.00452913\n",
      "I0000 00:00:1738060209.251903 1346389 random_forest.cc:891] Final OOB metrics: accuracy:0.999974 logloss:0.00452913\n",
      "I0000 00:00:1738060209.254551 1346389 kernel.cc:926] Export model in log directory: /var/folders/4t/vgrmglh57ds018mbdc9875y80000gn/T/tmpv3knixu4 with prefix 2e7fac9e21ed46ef\n",
      "I0000 00:00:1738060209.257124 1346389 kernel.cc:944] Save model in resources\n",
      "I0000 00:00:1738060209.260204 1330287 abstract_model.cc:914] Model self evaluation:\n",
      "Number of predictions (without weights): 429513\n",
      "Number of predictions (with weights): 429296\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.999974  CI95[W][0.999957 0.999985]\n",
      "LogLoss: : 0.00452913\n",
      "ErrorRate: : 2.58088e-05\n",
      "\n",
      "Default Accuracy: : 0.333599\n",
      "Default LogLoss: : 1.09861\n",
      "Default ErrorRate: : 0.666401\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "                   1                 2                  3\n",
      "1  143201.5296134949                 0  11.07068538665771\n",
      "2                  0  142929.726433754                  0\n",
      "3                  0                 0  143153.5360198021\n",
      "Total: 429295.8627524376\n",
      "\n",
      "\n",
      "2025-01-28 11:30:09.267439: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1206] Loading model from path /var/folders/4t/vgrmglh57ds018mbdc9875y80000gn/T/tmpv3knixu4/model/ with prefix 2e7fac9e21ed46ef\n",
      "I0000 00:00:1738060209.275714 1330287 decision_forest.cc:761] Model loaded with 50 root(s), 1590 node(s), and 5 input feature(s).\n",
      "I0000 00:00:1738060209.276169 1330287 abstract_model.cc:1404] Engine \"RandomForestGeneric\" built\n",
      "2025-01-28 11:30:09.276173: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1035] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: random_forest_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: random_forest_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to random_forest_model\n"
     ]
    }
   ],
   "source": [
    "best_features = features_with_humidity\n",
    "\n",
    "train_ds, val_ds, test_ds, y_test = prepare_data(best_features)\n",
    "\n",
    "with strategy.scope():\n",
    "    final_model = tfdf.keras.RandomForestModel(\n",
    "        num_trees=50,  \n",
    "        max_depth=7,  \n",
    "        min_examples=10,  \n",
    "        task=tfdf.keras.Task.CLASSIFICATION,\n",
    "        random_seed=42\n",
    "    )\n",
    "    final_model.compile(metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "final_model.fit(train_ds, validation_data=val_ds, verbose=1, class_weight=class_weights_dict)\n",
    "\n",
    "model_path = \"random_forest_model\"\n",
    "\n",
    "final_model.save(model_path , save_format=\"tf\")\n",
    "print(f\"Model saved to {model_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
